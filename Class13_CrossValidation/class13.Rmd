```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(fig.align="center", fig.height=3, fig.width=4)
```
## In-class worksheet 13
**Feb 27, 2018**
*Yao Zhang*

In this worksheet, we will use the libraries tidyverse, plotROC, and ggthemes:
```{r message=FALSE}
library(tidyverse)
theme_set(theme_bw(base_size=12)) # set default ggplot2 theme
library(plotROC)
library(ggthemes)
```

# 1. Working with training and test data sets

We continue working with the biopsy data set:
```{r}
biopsy <- read.csv("http://wilkelab.org/classes/SDS348/data_sets/biopsy.csv")
```

The following code splits the biopsy data set into a random training and test set:
```{r}
train_fraction <- 0.4 # fraction of data for training purposes
set.seed(126)  # set the seed to make the partition reproductible
train_size <- floor(train_fraction * nrow(biopsy)) # number of observations in training set
train_indices <- sample(1:nrow(biopsy), size = train_size)

train_data <- biopsy[train_indices, ] # get training data
test_data <- biopsy[-train_indices, ] # get test data
```

Fit a logistic regression model on the training data set, then predict the outcome on the test data set, and plot the resulting ROC curves. Limit the x-axis range from 0 to 0.15 to zoom into the ROC curve. (Hint: Do **not** use `coord_fixed()`.)
```{r}
# model to use: 
# outcome ~ clump_thickness + uniform_cell_size + uniform_cell_shape
glm.out <- glm(outcome ~ clump_thickness + uniform_cell_size + uniform_cell_shape,
    data = train_data,
    family = binomial())
df <- data.frame(predictor = predict(glm.out,test_data),
                  known_truth = test_data$outcome,
                  model = "Train0.4w_3variables")
# the aesthetic names are not the most intuitive
# `d` (disease) holds the known truth
# `m` (marker) holds the predictor values 
p <- ggplot(df, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0)
p
```

# 2. Area under the ROC curves

You can calculate the areas under the ROC curves by running `calc_auc()` on a plot generated with `geom_roc()` (see previous worksheet). Use this function to calculate the area under the training and test curve for the model `outcome ~ clump_thickness`. For this exercise, generate a new set of training and test datasets with a different fraction of training data from before.
```{r}
# Calculate AUC ROC for the last model
calc_auc(p)
# New model
train_fraction <- 0.7 # fraction of data for training purposes
set.seed(126)  # set the seed to make the partition reproductible
train_size <- floor(train_fraction * nrow(biopsy)) # number of observations in training set
train_indices <- sample(1:nrow(biopsy), size = train_size)

train_data <- biopsy[train_indices, ] # get training data
test_data <- biopsy[-train_indices, ] # get test data
# outcome ~ clump_thickness
glm.out <- glm(outcome ~ clump_thickness,
    data = train_data,
    family = binomial())
df2 <- data.frame(predictor = predict(glm.out,test_data),
                  known_truth = test_data$outcome,
                  model = "Train0.7w_clump_thickness")
# the aesthetic names are not the most intuitive
# `d` (disease) holds the known truth
# `m` (marker) holds the predictor values 
p2 <- ggplot(df2, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0)
p2
calc_auc(p2)
```

# 3. If this was easy

Write code that combines the AUC values calculated by `calc_auc()` with the correct group names and orders the output in descending order of AUC. (Hint: We have seen similar code in the previous worksheet.)

```{r}
df_combined <- rbind(df, df2)
p_combined <- ggplot(df_combined, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0) 
p_combined
# calc_auc(p_combined)
model <- unique(df_combined$model)
model_info <- data.frame(model,
                         group = order(model))
left_join(model_info, calc_auc(p_combined)) %>%
  select(-group, -PANEL) %>%
  arrange(desc(AUC))
```

Write code that generates an arbitrary number of random subdivisions of the data into training and test sets, fits a given model, calculates the area under the curve for each test data set, and then calculates the average and standard deviation of these values.
```{r warning=FALSE}
# function that does the heavy lifting
generate_AUC_values <- function(data, formula, train_fraction)
{
  n_obs <- nrow(data) # number of observations in data set
  train_size <- floor(train_fraction * nrow(data)) # number of observations in training set
  train_indices <- sample(1:n_obs, size = train_size)

  train_data <- data[train_indices, ] # get training data
  test_data <- data[-train_indices, ] # get test data
  glm.out <- glm(formula, data=train_data, family=binomial)

  df_train <- data.frame(predictor = predict(glm.out, train_data),
                       known_truth = train_data$outcome,
                       data_name = "AUC_train")

  df_test <- data.frame(predictor = predict(glm.out, test_data),
                       known_truth = test_data$outcome,
                       data_name = "AUC_test")

  df_combined <- rbind(df_train, df_test)
  p <- ggplot(df_combined, aes(d = known_truth, m = predictor, color = data_name)) + 
    geom_roc(n.cuts = 0)

  data_name <- unique(df_combined$data_name)
  data_info <- data.frame(data_name,
                          group = order(data_name))
  left_join(data_info, calc_auc(p)) %>%
    select(-group, -PANEL) %>%
    spread(data_name, AUC)
}

# example use
generate_AUC_values(biopsy,  outcome ~ clump_thickness, 0.2)

# function that does repeated random subsampling validation
subsample_validate <- function(data, formula, train_fraction, replicates)
{
  reps <- data.frame(rep=1:replicates) # dummy data frame to iterate over
  reps %>% group_by(rep) %>% # iterate over all replicates
    do(generate_AUC_values(data, formula, train_fraction)) %>% # run calc_AUC for each replicate
    ungroup() %>%     # ungroup so we can summarize
    summarize(mean_AUC_train = mean(AUC_train),        # summarize
              sd_AUC_train = sd(AUC_train),
              mean_AUC_test = mean(AUC_test),
              sd_AUC_test = sd(AUC_test)) %>%
    mutate(train_fraction=train_fraction, replicates=replicates) # add columns containing meta data
}

train_fraction <- 0.2 # fraction of data for training purposes
replicates <- 10 # how many times do we want to randomly sample
set.seed(116) # random seed
formula <- outcome ~ clump_thickness + normal_nucleoli # the model we want to fit
subsample_validate(biopsy, formula, train_fraction, replicates)

# redo with a different model
formula2 <- outcome ~ clump_thickness + normal_nucleoli + marg_adhesion
subsample_validate(biopsy, formula2, train_fraction, replicates)
```

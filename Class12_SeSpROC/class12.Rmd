```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(fig.align="center", fig.height=3, fig.width=4)
```
## In-class worksheet 12
**Feb 22, 2018**

In this worksheet, we will use the libraries tidyverse, ggthemes, and plotROC:
```{r message=FALSE}
library(tidyverse)
theme_set(theme_bw(base_size=12)) # set default ggplot2 theme
library(ggthemes) # for scale_color_colorblind()

# install.packages("plotROC")
library(plotROC) # for geom_roc() and calc_auc()
```

# 1. True positive and true negative rates

We continue working with the two species virginica and versicolor from the `iris` data set. As was done in the previous class, the following code makes a reduced data set, fits a logistic regression model (this time using only `Sepal.Length` as predictor), and then combines the predicted probabilities and the known species identity into one data frame called `pred_data`:
```{r}
# make a reduced iris data set that only contains virginica and versicolor species
iris.small <- filter(iris, Species %in% c("virginica", "versicolor")) %>%
  mutate(Species = factor(Species)) # this makes R forget about the 3rd species

# fit logistic regression model
glm.out <- glm(Species ~ Sepal.Length,
               data = iris.small,
               family = binomial)

# combine fitted values and Species identity
pred_data <- data.frame(probability = glm.out$fitted.values,
                        Species = iris.small$Species)
```

Pick a probability cutoff at which you would decide that a specimen belongs to virginica rather than versicolor. Calculate how many virginicas you call correctly and how many incorrectly given that cutoff. Hint: use the functions `filter()` and `tally()`.
```{r}
pred_data %>% ggplot(aes(x=probability,fill=Species))+geom_density(alpha=0.5)
# I will pick a probability cutoff == 0.45, greater -> virginica, otherwise, veresicolor
cutoff = 0.5
# How many virginicas I call correctly
true.vir <- pred_data %>% filter(Species=='virginica' & probability>cutoff) %>% tally()
# How many incorrectly given that cutff
false.vir <- pred_data %>% filter(Species=='virginica' & probability<=cutoff) %>% tally()
```

Now do the same calculation for versicolor.
```{r}
# How many versicolor I call correctly
true.ver <- pred_data %>% filter(Species=='versicolor' & probability<=cutoff) %>% tally()
# How many incorrectly given that cutff
false.ver <- pred_data %>% filter(Species=='versicolor' & probability>cutoff) %>% tally()
```

If we define a call of virginica as a positive and a call of versicolor as a negative, what are the true positive rate (sensitivity, true positives divided by all possible positives, i.e., by the total count of virginicas) and the true negative rate (specificity, true negatives divided by all possible negatives, i.e., by the total count of versicolors) in your analysis?
```{r}
# true positive rate
TPR <- true.vir/(true.vir+false.vir)
TPR
# true negative rate
TNR <- true.ver/(true.ver+false.ver)
TNR
```

Recalculate the true-positive rate and the true-negative rate for a different probability cutoff.
```{r}
cutoff = 0.1 # Checked. Correct.
# How many virginicas I call correctly
true.vir <- pred_data %>% filter(Species=='virginica' & probability>=cutoff) %>% tally()
# How many incorrectly given that cutff
false.vir <- pred_data %>% filter(Species=='virginica' & probability<cutoff) %>% tally()
# How many versicolor I call correctly
true.ver <- pred_data %>% filter(Species=='versicolor' & probability<cutoff) %>% tally()
# How many incorrectly given that cutff
false.ver <- pred_data %>% filter(Species=='versicolor' & probability>=cutoff) %>% tally()
# true positive rate
TPR <- true.vir/(true.vir+false.vir)
TPR
# true negative rate
TNR <- true.ver/(true.ver+false.ver)
TNR
```

# 2. ROC curves

Next we will calculate and plot ROC curves. We do this with the function `geom_roc()` from the package plotROC. Here is an example:

```{r}
# fit the model
glm.out <- glm(Species ~ Sepal.Width,
               data = iris.small,
               family = binomial)

# make data frame of the linear predictor and the known truth
df1 <- data.frame(predictor = predict(glm.out, iris.small), # linear predictor
                  known_truth = iris.small$Species,  # the known truth, i.e., true species assignment
                  model = "Sepal.Width")             # an arbitrary name to distinguish different curves

# plot

# the aesthetic names are not the most intuitive
# `d` (disease) holds the known truth
# `m` (marker) holds the predictor values 
p1 <- ggplot(df1, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0) +
  coord_fixed() + scale_color_colorblind()
p1
```

Now make a few additional models and then make a plot showing the various ROC curves in one graph. (Hint: combine the data frames from the different models into one using the function `rbind()`.)

```{r fig.width=5}
# fit the model 2
glm.out <- glm(Species ~ Sepal.Width + Sepal.Length,
               data = iris.small,
               family = binomial)

# make data frame of the linear predictor and the known truth
df2 <- data.frame(predictor = predict(glm.out, iris.small), # linear predictor
                  known_truth = iris.small$Species,  # the known truth, i.e., true species assignment
                  model = "Sepal.Width and Length")             # an arbitrary name to distinguish different curves
ggplot(df2, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0) +
  coord_fixed() + scale_color_colorblind()

# fit the model 3
glm.out <- glm(Species ~ Sepal.Width + Sepal.Length +Petal.Length + Petal.Width,
               data = iris.small,
               family = binomial)

# make data frame of the linear predictor and the known truth
df3 <- data.frame(predictor = predict(glm.out, iris.small), # linear predictor
                  known_truth = iris.small$Species,  # the known truth, i.e., true species assignment
                  model = "All")             # an arbitrary name to distinguish different curves
ggplot(df3, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0) +
  coord_fixed() + scale_color_colorblind()

# combine
df.all <- rbind(df1,df2,df3)
p <- ggplot(df.all, aes(d = known_truth, m = predictor, color = model)) + 
  geom_roc(n.cuts = 0) +
  coord_fixed() + scale_color_colorblind()
p
```


# 3. If this was easy

Calculate the area under the ROC curve (AUC) for your first model, using the function `calc_auc()` from the plotROC package. This function needs to be called on a plot containing a `geom_roc()` statement.

```{r}
calc_auc(p1)
```

Now calculate the AUC values for all the ROC curves you generated earlier, using the function `calc_auc()` exactly once.

```{r}
table0 <- calc_auc(p)
```

Unfortunately, because of how ggplot works, we have now lost the model names and instead just have group numbers. We can recover the connection between model name and group number by calling `unique(df_combined$model)` to obtain the model names and `order(unique(df_combined$model))` to obtain the corresponding group numbers. Use this information to generate a modified table that contains model name and AUC and is sorted in descending order of AUC.

```{r}
table.mod <- data.frame(table0, Model = unique(df.all$model))
order(unique(df.all$model))
table.mod
```